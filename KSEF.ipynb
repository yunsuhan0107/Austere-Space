{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# 랜덤시드 고정시키기\n",
    "np.random.seed(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 711 images belonging to 2 classes.\n",
      "Found 324 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 생성하기\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',\n",
    "        target_size=(32, 32), \n",
    "        batch_size=3,\n",
    "        class_mode='binary') \n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'data/test',\n",
    "        target_size=(32, 32),     \n",
    "        batch_size=3,\n",
    "        class_mode='binary') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 모델 구성하기\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', input_shape=(32,32, 3)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 모델 학습과정 설정하기\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "10/10 [==============================] - 3s 295ms/step - loss: 6.6444 - accuracy: 0.5667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 2s 155ms/step - loss: 7.6666 - accuracy: 0.5000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 2s 156ms/step - loss: 8.6888 - accuracy: 0.4333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 2s 157ms/step - loss: 6.1333 - accuracy: 0.6000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 2s 162ms/step - loss: 6.6444 - accuracy: 0.5667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 2s 159ms/step - loss: 7.1555 - accuracy: 0.5333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 2s 168ms/step - loss: 8.1777 - accuracy: 0.4667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 2s 178ms/step - loss: 5.6222 - accuracy: 0.6333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 2s 167ms/step - loss: 6.6444 - accuracy: 0.5667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 2s 167ms/step - loss: 7.1555 - accuracy: 0.5333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 2s 166ms/step - loss: 7.6666 - accuracy: 0.5000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 2s 167ms/step - loss: 5.6222 - accuracy: 0.6333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 2s 168ms/step - loss: 6.1333 - accuracy: 0.6000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 2s 168ms/step - loss: 5.1111 - accuracy: 0.6667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 2s 167ms/step - loss: 5.6222 - accuracy: 0.6333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 2s 168ms/step - loss: 5.1111 - accuracy: 0.6667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 2s 172ms/step - loss: 7.1555 - accuracy: 0.5333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 2s 170ms/step - loss: 5.6222 - accuracy: 0.6333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 2s 187ms/step - loss: 7.6666 - accuracy: 0.5000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 2s 183ms/step - loss: 5.6222 - accuracy: 0.6333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 2s 174ms/step - loss: 7.1555 - accuracy: 0.5333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 5.6222 - accuracy: 0.6333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 2s 229ms/step - loss: 6.1333 - accuracy: 0.6000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 4.0889 - accuracy: 0.7333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 2s 195ms/step - loss: 3.0666 - accuracy: 0.8000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 2s 247ms/step - loss: 7.6666 - accuracy: 0.5000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 2s 232ms/step - loss: 5.1111 - accuracy: 0.6667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 2s 179ms/step - loss: 5.6222 - accuracy: 0.6333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 2s 172ms/step - loss: 8.1777 - accuracy: 0.4667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 2s 171ms/step - loss: 8.1777 - accuracy: 0.4667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 2s 177ms/step - loss: 7.1555 - accuracy: 0.5333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 2s 174ms/step - loss: 8.6888 - accuracy: 0.4333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 2s 188ms/step - loss: 9.1999 - accuracy: 0.4000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 2s 172ms/step - loss: 5.1111 - accuracy: 0.6667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 2s 174ms/step - loss: 7.1555 - accuracy: 0.5333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 2s 176ms/step - loss: 3.5778 - accuracy: 0.7667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 2s 174ms/step - loss: 8.1777 - accuracy: 0.4667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 2s 174ms/step - loss: 6.1333 - accuracy: 0.6000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 2s 173ms/step - loss: 6.1333 - accuracy: 0.6000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 2s 172ms/step - loss: 7.1555 - accuracy: 0.5333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 2s 174ms/step - loss: 5.1111 - accuracy: 0.6667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 2s 172ms/step - loss: 6.6444 - accuracy: 0.5667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 2s 173ms/step - loss: 7.6666 - accuracy: 0.5000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 2s 172ms/step - loss: 4.6000 - accuracy: 0.7000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 2s 187ms/step - loss: 4.6000 - accuracy: 0.7000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 2s 172ms/step - loss: 6.6444 - accuracy: 0.5667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 2s 174ms/step - loss: 8.1777 - accuracy: 0.4667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 2s 176ms/step - loss: 4.6000 - accuracy: 0.7000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 2s 181ms/step - loss: 6.6444 - accuracy: 0.5667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 2s 177ms/step - loss: 5.6222 - accuracy: 0.6333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 2s 187ms/step - loss: 9.1999 - accuracy: 0.4000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 2s 173ms/step - loss: 8.1777 - accuracy: 0.4667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 2s 181ms/step - loss: 7.6666 - accuracy: 0.5000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 2s 177ms/step - loss: 4.6000 - accuracy: 0.7000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 2s 183ms/step - loss: 6.6444 - accuracy: 0.5667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 2s 178ms/step - loss: 6.1333 - accuracy: 0.6000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 172ms/step - loss: 6.1333 - accuracy: 0.6000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 2s 178ms/step - loss: 6.1333 - accuracy: 0.6000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 2s 176ms/step - loss: 8.1777 - accuracy: 0.4667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 2s 174ms/step - loss: 8.6888 - accuracy: 0.4333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 2s 174ms/step - loss: 5.6222 - accuracy: 0.6333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 2s 200ms/step - loss: 6.6444 - accuracy: 0.5667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 4.6000 - accuracy: 0.7000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 2s 179ms/step - loss: 8.6888 - accuracy: 0.4333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 2s 173ms/step - loss: 5.6222 - accuracy: 0.6333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 2s 172ms/step - loss: 6.1333 - accuracy: 0.6000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 2s 178ms/step - loss: 6.6444 - accuracy: 0.5667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 2s 199ms/step - loss: 6.6444 - accuracy: 0.5667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 2s 188ms/step - loss: 5.6222 - accuracy: 0.6333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 2s 173ms/step - loss: 5.1111 - accuracy: 0.6667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 2s 181ms/step - loss: 5.6222 - accuracy: 0.6333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 2s 178ms/step - loss: 6.1333 - accuracy: 0.6000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 2s 175ms/step - loss: 4.0889 - accuracy: 0.7333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 2s 172ms/step - loss: 5.1111 - accuracy: 0.6667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 2s 173ms/step - loss: 6.6444 - accuracy: 0.5667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 2s 175ms/step - loss: 8.6888 - accuracy: 0.4333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 2s 173ms/step - loss: 5.6222 - accuracy: 0.6333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 2s 175ms/step - loss: 6.6444 - accuracy: 0.5667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 2s 180ms/step - loss: 7.1555 - accuracy: 0.5333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 6.6444 - accuracy: 0.5667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 5.6222 - accuracy: 0.6333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 2s 176ms/step - loss: 7.6666 - accuracy: 0.5000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 2s 174ms/step - loss: 6.1333 - accuracy: 0.6000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 2s 170ms/step - loss: 8.1777 - accuracy: 0.4667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 2s 176ms/step - loss: 3.5778 - accuracy: 0.7667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 2s 190ms/step - loss: 6.1333 - accuracy: 0.6000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 2s 185ms/step - loss: 6.1333 - accuracy: 0.6000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 2s 178ms/step - loss: 8.6888 - accuracy: 0.4333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 2s 173ms/step - loss: 6.6444 - accuracy: 0.5667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 2s 171ms/step - loss: 8.1777 - accuracy: 0.4667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 2s 179ms/step - loss: 5.1111 - accuracy: 0.6667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 6.6444 - accuracy: 0.5667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 2s 178ms/step - loss: 7.6666 - accuracy: 0.5000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 2s 177ms/step - loss: 5.6222 - accuracy: 0.6333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 2s 178ms/step - loss: 7.1555 - accuracy: 0.5333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 2s 176ms/step - loss: 8.6888 - accuracy: 0.4333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 2s 174ms/step - loss: 5.1111 - accuracy: 0.6667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 2s 191ms/step - loss: 7.1555 - accuracy: 0.5333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 2s 175ms/step - loss: 9.7111 - accuracy: 0.3667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 2s 177ms/step - loss: 5.6222 - accuracy: 0.6333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 2s 178ms/step - loss: 5.6222 - accuracy: 0.6333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 2s 182ms/step - loss: 6.1333 - accuracy: 0.6000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 2s 183ms/step - loss: 6.1333 - accuracy: 0.6000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 2s 186ms/step - loss: 5.6222 - accuracy: 0.6333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 6.1333 - accuracy: 0.6000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 2s 208ms/step - loss: 7.6666 - accuracy: 0.5000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 2s 200ms/step - loss: 3.5778 - accuracy: 0.7667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 6.1333 - accuracy: 0.6000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 2s 204ms/step - loss: 5.6222 - accuracy: 0.6333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 2s 209ms/step - loss: 5.1111 - accuracy: 0.6667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 2s 194ms/step - loss: 4.0889 - accuracy: 0.7333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 2s 208ms/step - loss: 7.1555 - accuracy: 0.5333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 241ms/step - loss: 4.0889 - accuracy: 0.7333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 2s 192ms/step - loss: 6.6444 - accuracy: 0.5667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 2s 188ms/step - loss: 8.1777 - accuracy: 0.4667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 2s 176ms/step - loss: 7.6666 - accuracy: 0.5000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 2s 185ms/step - loss: 4.0889 - accuracy: 0.7333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 2s 237ms/step - loss: 10.7333 - accuracy: 0.3000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 2s 244ms/step - loss: 7.6666 - accuracy: 0.5000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 2s 195ms/step - loss: 6.1333 - accuracy: 0.6000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 2s 181ms/step - loss: 5.6222 - accuracy: 0.6333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 2s 177ms/step - loss: 6.1333 - accuracy: 0.6000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 2s 182ms/step - loss: 7.1555 - accuracy: 0.5333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 2s 181ms/step - loss: 7.6666 - accuracy: 0.5000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 2s 182ms/step - loss: 5.6222 - accuracy: 0.6333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 2s 177ms/step - loss: 8.6888 - accuracy: 0.4333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 2s 180ms/step - loss: 6.1333 - accuracy: 0.6000 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 2s 178ms/step - loss: 5.1111 - accuracy: 0.6667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 5.1111 - accuracy: 0.6667 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 2s 188ms/step - loss: 7.1555 - accuracy: 0.5333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 2s 182ms/step - loss: 7.1555 - accuracy: 0.5333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 2s 182ms/step - loss: 5.6222 - accuracy: 0.6333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 2s 177ms/step - loss: 7.1555 - accuracy: 0.5333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 2s 201ms/step - loss: 5.6222 - accuracy: 0.6333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 2s 192ms/step - loss: 7.1555 - accuracy: 0.5333 - val_loss: 6.1333 - val_accuracy: 0.6000\n",
      "Epoch 136/1000\n",
      " 7/10 [====================>.........] - ETA: 0s - loss: 8.0317 - accuracy: 0.4762"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c35ca7ac0ce2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         validation_steps=5)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3215\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3216\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3217\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3218\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n\u001b[1;32m   3219\u001b[0m                                  [x.numpy() for x in outputs])\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    557\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 558\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    413\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    414\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 415\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    416\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     59\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 4. 모델 학습시키기\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=10, \n",
    "        epochs=1000,  \n",
    "        validation_data=test_generator,\n",
    "        validation_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate_generator(test_generator, steps=5)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# 6. 모델 사용하기\n",
    "print(\"-- Predict --\")\n",
    "output = model.predict_generator(test_generator, steps=5)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "print(test_generator.class_indices)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
