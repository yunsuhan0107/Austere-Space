{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def recall(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
    "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
    "\n",
    "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n",
    "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
    "\n",
    "    # Precision = (True Positive) / (True Positive + False Positive)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1score(y_target, y_pred):\n",
    "    _recall = recall(y_target, y_pred)\n",
    "    _precision = precision(y_target, y_pred)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
    "    \n",
    "    # return a single tensor value\n",
    "    return _f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 711 images belonging to 2 classes.\n",
      "Found 324 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 생성하기\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                   rotation_range=10,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.7,\n",
    "                                   zoom_range=[0.9, 2.2],\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',\n",
    "        target_size=(32, 32),\n",
    "        batch_size=3,\n",
    "        class_mode='binary') \n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'data/test',\n",
    "        target_size=(32, 32),     \n",
    "        batch_size=3,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda2\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1394: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.8357 - accuracy: 0.5667 - precision: 0.4500 - recall: 0.6300 - f1score: 0.5007 - val_loss: 0.6963 - val_accuracy: 0.4667 - val_precision: 0.2000 - val_recall: 0.2000 - val_f1score: 0.2000\n",
      "Epoch 2/500\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.7190 - accuracy: 0.6133 - precision: 0.5633 - recall: 0.7433 - f1score: 0.6073 - val_loss: 0.6859 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: 0.0000e+00\n",
      "Epoch 3/500\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.7788 - accuracy: 0.5467 - precision: 0.4433 - recall: 0.5800 - f1score: 0.4680 - val_loss: 0.6860 - val_accuracy: 0.6000 - val_precision: 0.6000 - val_recall: 1.0000 - val_f1score: 0.7200\n",
      "Epoch 4/500\n",
      "50/50 [==============================] - 2s 37ms/step - loss: 0.7406 - accuracy: 0.5867 - precision: 0.5567 - recall: 0.5267 - f1score: 0.5027 - val_loss: 0.6161 - val_accuracy: 0.7333 - val_precision: 0.8000 - val_recall: 0.8333 - val_f1score: 0.7933\n",
      "Epoch 5/500\n",
      "50/50 [==============================] - 2s 40ms/step - loss: 0.6702 - accuracy: 0.6800 - precision: 0.7400 - recall: 0.8667 - f1score: 0.7500 - val_loss: 0.5546 - val_accuracy: 0.7333 - val_precision: 0.8333 - val_recall: 0.8333 - val_f1score: 0.7867\n",
      "Epoch 6/500\n",
      "50/50 [==============================] - 2s 37ms/step - loss: 0.6308 - accuracy: 0.7000 - precision: 0.6467 - recall: 0.6833 - f1score: 0.6207 - val_loss: 0.6480 - val_accuracy: 0.6000 - val_precision: 0.6000 - val_recall: 1.0000 - val_f1score: 0.7200\n",
      "Epoch 7/500\n",
      "50/50 [==============================] - 2s 37ms/step - loss: 0.5719 - accuracy: 0.7533 - precision: 0.7533 - recall: 0.8100 - f1score: 0.7380 - val_loss: 0.9769 - val_accuracy: 0.2000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: 0.0000e+00\n",
      "Epoch 8/500\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.6930 - accuracy: 0.6133 - precision: 0.5900 - recall: 0.6867 - f1score: 0.6000 - val_loss: 0.6804 - val_accuracy: 0.6667 - val_precision: 0.6333 - val_recall: 0.8000 - val_f1score: 0.6933\n",
      "Epoch 9/500\n",
      "50/50 [==============================] - 2s 37ms/step - loss: 0.7377 - accuracy: 0.5933 - precision: 0.6133 - recall: 0.6433 - f1score: 0.5667 - val_loss: 0.6372 - val_accuracy: 0.6000 - val_precision: 0.6000 - val_recall: 1.0000 - val_f1score: 0.7200\n",
      "Epoch 10/500\n",
      "50/50 [==============================] - 2s 37ms/step - loss: 0.5633 - accuracy: 0.7200 - precision: 0.7867 - recall: 0.8000 - f1score: 0.7520 - val_loss: 0.6561 - val_accuracy: 0.6000 - val_precision: 0.6000 - val_recall: 1.0000 - val_f1score: 0.7200\n",
      "Epoch 11/500\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.7324 - accuracy: 0.6600 - precision: 0.6167 - recall: 0.6833 - f1score: 0.6100 - val_loss: 0.7847 - val_accuracy: 0.6667 - val_precision: 0.6333 - val_recall: 1.0000 - val_f1score: 0.7533\n",
      "Epoch 12/500\n",
      "50/50 [==============================] - 2s 37ms/step - loss: 0.7093 - accuracy: 0.6133 - precision: 0.5933 - recall: 0.6833 - f1score: 0.5927 - val_loss: 0.6620 - val_accuracy: 0.7333 - val_precision: 0.6333 - val_recall: 0.8000 - val_f1score: 0.6933\n",
      "Epoch 13/500\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.5330 - accuracy: 0.7200 - precision: 0.6900 - recall: 0.7767 - f1score: 0.6987 - val_loss: 0.4660 - val_accuracy: 0.7333 - val_precision: 0.8333 - val_recall: 0.8333 - val_f1score: 0.7867\n",
      "Epoch 14/500\n",
      "50/50 [==============================] - 2s 42ms/step - loss: 0.5437 - accuracy: 0.7533 - precision: 0.7133 - recall: 0.7500 - f1score: 0.7013 - val_loss: 0.3670 - val_accuracy: 0.7333 - val_precision: 0.8333 - val_recall: 0.8333 - val_f1score: 0.7867\n",
      "Epoch 15/500\n",
      "50/50 [==============================] - 2s 37ms/step - loss: 0.4980 - accuracy: 0.8267 - precision: 0.7800 - recall: 0.8133 - f1score: 0.7707 - val_loss: 0.4401 - val_accuracy: 0.8000 - val_precision: 0.7667 - val_recall: 1.0000 - val_f1score: 0.8533\n",
      "Epoch 16/500\n",
      "50/50 [==============================] - 2s 36ms/step - loss: 0.5023 - accuracy: 0.8133 - precision: 0.7700 - recall: 0.7967 - f1score: 0.7600 - val_loss: 0.4591 - val_accuracy: 0.8000 - val_precision: 0.9333 - val_recall: 0.8333 - val_f1score: 0.8533\n",
      "Epoch 17/500\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.3690 - accuracy: 0.8467 - precision: 0.7900 - recall: 0.8167 - f1score: 0.7840 - val_loss: 0.3570 - val_accuracy: 0.8000 - val_precision: 0.7667 - val_recall: 1.0000 - val_f1score: 0.8533\n",
      "Epoch 18/500\n",
      "50/50 [==============================] - 2s 36ms/step - loss: 0.3508 - accuracy: 0.8733 - precision: 0.8167 - recall: 0.8100 - f1score: 0.8013 - val_loss: 0.3098 - val_accuracy: 0.8000 - val_precision: 0.9333 - val_recall: 0.8333 - val_f1score: 0.8533\n",
      "Epoch 19/500\n",
      "50/50 [==============================] - 2s 37ms/step - loss: 0.4604 - accuracy: 0.8400 - precision: 0.7967 - recall: 0.8133 - f1score: 0.7840 - val_loss: 0.9095 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1score: 0.8933\n",
      "Epoch 20/500\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.4981 - accuracy: 0.8400 - precision: 0.8333 - recall: 0.8500 - f1score: 0.8120 - val_loss: 0.4604 - val_accuracy: 0.8000 - val_precision: 0.7667 - val_recall: 1.0000 - val_f1score: 0.8533\n",
      "Epoch 21/500\n",
      "50/50 [==============================] - 2s 36ms/step - loss: 0.3910 - accuracy: 0.9000 - precision: 0.8300 - recall: 0.8933 - f1score: 0.8453 - val_loss: 0.3448 - val_accuracy: 0.8667 - val_precision: 0.9333 - val_recall: 0.9333 - val_f1score: 0.9200\n",
      "Epoch 22/500\n",
      "50/50 [==============================] - 2s 36ms/step - loss: 0.3478 - accuracy: 0.8867 - precision: 0.7733 - recall: 0.8233 - f1score: 0.7800 - val_loss: 0.3217 - val_accuracy: 0.8000 - val_precision: 0.9333 - val_recall: 0.8333 - val_f1score: 0.8533\n",
      "Epoch 23/500\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.2330 - accuracy: 0.9200 - precision: 0.8333 - recall: 0.8567 - f1score: 0.8340 - val_loss: 0.8042 - val_accuracy: 0.6667 - val_precision: 0.7000 - val_recall: 0.6333 - val_f1score: 0.6600\n",
      "Epoch 24/500\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.2660 - accuracy: 0.9067 - precision: 0.9033 - recall: 0.9167 - f1score: 0.8960 - val_loss: 0.4256 - val_accuracy: 0.8000 - val_precision: 0.9333 - val_recall: 0.8333 - val_f1score: 0.8533\n",
      "Epoch 25/500\n",
      "50/50 [==============================] - 2s 37ms/step - loss: 0.2951 - accuracy: 0.8600 - precision: 0.7867 - recall: 0.8033 - f1score: 0.7827 - val_loss: 0.3291 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1score: 0.8933\n",
      "Epoch 26/500\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.4085 - accuracy: 0.8267 - precision: 0.7933 - recall: 0.7700 - f1score: 0.7600 - val_loss: 0.3065 - val_accuracy: 0.8000 - val_precision: 0.9333 - val_recall: 0.8333 - val_f1score: 0.8533\n",
      "Epoch 27/500\n",
      "50/50 [==============================] - 2s 36ms/step - loss: 0.2913 - accuracy: 0.8933 - precision: 0.8167 - recall: 0.8867 - f1score: 0.8340 - val_loss: 0.2651 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.8000 - val_f1score: 0.8667\n",
      "Epoch 28/500\n",
      "50/50 [==============================] - 2s 37ms/step - loss: 0.3542 - accuracy: 0.8467 - precision: 0.8300 - recall: 0.8567 - f1score: 0.8213 - val_loss: 2.5710 - val_accuracy: 0.4000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1score: 0.0000e+00\n",
      "Epoch 29/500\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.3794 - accuracy: 0.8800 - precision: 0.8233 - recall: 0.8833 - f1score: 0.8360 - val_loss: 0.1911 - val_accuracy: 0.9333 - val_precision: 0.9333 - val_recall: 1.0000 - val_f1score: 0.9600\n",
      "Epoch 30/500\n",
      "50/50 [==============================] - 2s 37ms/step - loss: 0.2580 - accuracy: 0.8867 - precision: 0.8467 - recall: 0.8367 - f1score: 0.8273 - val_loss: 0.1739 - val_accuracy: 0.9333 - val_precision: 1.0000 - val_recall: 0.9333 - val_f1score: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/500\n",
      "50/50 [==============================] - 2s 36ms/step - loss: 0.2059 - accuracy: 0.9267 - precision: 0.8533 - recall: 0.8700 - f1score: 0.8560 - val_loss: 0.3804 - val_accuracy: 0.8667 - val_precision: 1.0000 - val_recall: 0.8333 - val_f1score: 0.8933\n",
      "Epoch 32/500\n",
      "50/50 [==============================] - 2s 38ms/step - loss: 0.2998 - accuracy: 0.9200 - precision: 0.7933 - recall: 0.8433 - f1score: 0.8067 - val_loss: 0.1977 - val_accuracy: 0.9333 - val_precision: 0.9333 - val_recall: 1.0000 - val_f1score: 0.9600\n",
      "Epoch 33/500\n",
      "50/50 [==============================] - 2s 36ms/step - loss: 0.2645 - accuracy: 0.9133 - precision: 0.8267 - recall: 0.8900 - f1score: 0.8440 - val_loss: 0.4943 - val_accuracy: 0.6667 - val_precision: 0.6000 - val_recall: 0.4667 - val_f1score: 0.5000\n",
      "Epoch 34/500\n",
      " 9/50 [====>.........................] - ETA: 1s - loss: 0.2453 - accuracy: 0.8519 - precision: 0.7222 - recall: 0.7407 - f1score: 0.7185"
     ]
    }
   ],
   "source": [
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='elu', input_shape=(32,32, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='elu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001)\n",
    "#                  ,loss=tf.keras.losses.binary_crossentropy\n",
    "#                  ,metrics=[tf.keras.metrics.Precision(name='precision')\\\n",
    "#                           ,tf.keras.metrics.Recall(name='recall')\\\n",
    "#                           ,tf.keras.metrics.FalsePositives(name='false_positives')\\\n",
    "#                           ,tf.keras.metrics.FalseNegatives(name='false_negatives')])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', precision, recall, f1score])\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10) # 조기종료 콜백함수 정의\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "hist = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=50, \n",
    "        epochs=500,  \n",
    "        validation_data=test_generator,\n",
    "        validation_steps=5,\n",
    "        callbacks=[early_stopping])\n",
    "\n",
    "_loss, _acc, _precision, _recall, _f1score = model.evaluate_generator(test_generator, steps=5)\n",
    "print('loss: {:.3f}, accuracy: {:.3f}, precision: {:.3f}, recall: {:.3f}, f1score: {:.3f}'.format(_loss, _acc, _precision, _recall, _f1score))\n",
    "\n",
    "\n",
    "# # 5. 모델 평가하기\n",
    "# print(\"-- Evaluate --\")\n",
    "# scores = model.evaluate_generator(test_generator, steps=5)\n",
    "# print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# # 6. 모델 사용하기\n",
    "# print(\"-- Predict --\")\n",
    "# output = model.predict_generator(test_generator, steps=5)\n",
    "# np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "# print(test_generator.class_indices)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate_generator(test_generator, steps=5)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# # 6. 모델 사용하기\n",
    "print(\"-- Predict --\")\n",
    "output = model.predict_generator(test_generator, steps=5)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "print(test_generator.class_indices)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['val_precision'], 'r', label='val precision')\n",
    "\n",
    "acc_ax.plot(hist.history['val_recall'], 'g', label='val recall')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('precision')\n",
    "acc_ax.set_ylabel('recall')\n",
    "\n",
    "loss_ax.legend(loc='lower right')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['val_f1score'], 'r', label='val precision')\n",
    "\n",
    "\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('f1score')\n",
    "\n",
    "\n",
    "loss_ax.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
